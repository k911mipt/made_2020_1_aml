{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced ML: Домашнее задание 4\n",
    "\n",
    "Четвёртое домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как и раньше, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются. \n",
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена, которые выглядели примерно так:\n",
    "\n",
    "![](./dancing_men.png)\n",
    "\n",
    "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода. В качестве корпусов текстов для подсчётов частот можете взять что угодно, но для удобства вот вам “Война и мир” по-русски и по-английски:\n",
    "\n",
    "[corpora.zip](./corpora.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:33.754260Z",
     "start_time": "2020-06-24T05:53:33.682243Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:33.767263Z",
     "start_time": "2020-06-24T05:53:33.755259Z"
    }
   },
   "outputs": [],
   "source": [
    "alphabet = list('абвгдеёжзийклмнопрстуфхцчшщъыьэюя ')\n",
    "def read_file_from_archive(archive, name):\n",
    "    return archive.read(name).decode(\"utf-8\").replace('\\t', ' ')\n",
    "\n",
    "def read_files():\n",
    "    archive = zipfile.ZipFile('corpora.zip', 'r')\n",
    "    str_anna = read_file_from_archive(archive, \"AnnaKarenina.txt\")\n",
    "    str_war = read_file_from_archive(archive, \"WarAndPeace.txt\")\n",
    "    str_war_eng = read_file_from_archive(archive, \"WarAndPeaceEng.txt\")\n",
    "    return str_anna, str_war, str_war_eng\n",
    "\n",
    "def filter_text(text, alphabet):\n",
    "    return ' '.join(''.join([ch if ch in alphabet else ' ' for ch in text.lower()]).split())\n",
    "\n",
    "def get_ngram_count(text, n):\n",
    "    return Counter([text[i:i+n] for i in range(len(text) - n + 1)])\n",
    "\n",
    "def calc_frequenties(text, n_gram):\n",
    "    freq_dict = get_ngram_count(text, n_gram)\n",
    "    sum_freqs = sum(freq_dict.values())\n",
    "    return Counter({k: v / sum_freqs for k, v in freq_dict.items()})\n",
    "\n",
    "def get_cipher_alphabet(alphabet):\n",
    "    cipher_alphabet = [ord(x) for x in alphabet]\n",
    "    cipher_alphabet = [chr(x + 500) for x in cipher_alphabet]\n",
    "#     random.Random(42).shuffle(cipher_alphabet) \n",
    "    np.random.shuffle(cipher_alphabet) \n",
    "    return cipher_alphabet\n",
    "\n",
    "def get_cipher_dict(alphabet):\n",
    "    cipher_dict = dict.fromkeys(alphabet, '')\n",
    "    cipher_alphabet = get_cipher_alphabet(alphabet)\n",
    "    for i in range(len(alphabet)):\n",
    "        cipher_dict[alphabet[i]] = cipher_alphabet[i]\n",
    "    return cipher_dict\n",
    "\n",
    "def get_map_dict(freques_alphabet, freques_text):\n",
    "    alphabet_freq = [x[0] for x in freques_alphabet.most_common()]\n",
    "    text_freq = [x[0] for x in freques_text.most_common()]\n",
    "    return dict(zip(text_freq, alphabet_freq))\n",
    "        \n",
    "def cipher(text, cipher_dict):\n",
    "    return ''.join(cipher_dict[ch] for ch in text if ch in cipher_dict)\n",
    "\n",
    "def replace_ngram(text, map_dict, n_gram):\n",
    "    null_ch = chr(0)\n",
    "    replaced = [null_ch for i in range(len(text))]\n",
    "    for k, v in map_dict.items():\n",
    "        i_s = text.find(k)\n",
    "        while i_s != -1:\n",
    "            for i in range(n_gram):\n",
    "                if replaced[i_s + i] == null_ch:\n",
    "                    replaced[i_s + i] = v[i]\n",
    "            i_s = text.find(k, i_s + 1)\n",
    "    return ''.join(replaced)\n",
    "\n",
    "def get_letter_accuracy(orig_text, deciphered_text):\n",
    "    good = 0\n",
    "    for i in range(len(orig_text)):\n",
    "        if orig_text[i] == deciphered_text[i]:\n",
    "            good +=1\n",
    "    return good / len(orig_text)\n",
    "\n",
    "def freque_decipher(etalon_text, ciphered_text, n_gram):\n",
    "    freques_alphabet = calc_frequenties(etalon_text, n_gram)\n",
    "    freques_text = calc_frequenties(ciphered_text, n_gram)\n",
    "    decipher_dict = get_map_dict(freques_alphabet, freques_text)\n",
    "    return replace_ngram(ciphered_text, decipher_dict, n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:34.557441Z",
     "start_time": "2020-06-24T05:53:33.768262Z"
    }
   },
   "outputs": [],
   "source": [
    "str_anna, str_war, str_war_eng = read_files()\n",
    "rus_text = filter_text(str_anna + str_war, alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "\n",
    "* подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "* возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "* расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:35.108565Z",
     "start_time": "2020-06-24T05:53:34.558441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'а': 0.06940753885954973,\n",
       "         'н': 0.056983173333903486,\n",
       "         ' ': 0.16590579632678368,\n",
       "         'к': 0.028987192918688932,\n",
       "         'р': 0.034576553847469584,\n",
       "         'е': 0.07105642385238717,\n",
       "         'и': 0.05546684911590515,\n",
       "         'о': 0.09565371704688803,\n",
       "         'д': 0.02480981804964615,\n",
       "         'з': 0.013992858822774797,\n",
       "         'с': 0.04415214556028308,\n",
       "         'м': 0.024146158944645186,\n",
       "         'ы': 0.01558529858245494,\n",
       "         'х': 0.00666481366658827,\n",
       "         'т': 0.04928609608518099,\n",
       "         'в': 0.03907806119176413,\n",
       "         'л': 0.04198798400718394,\n",
       "         'ь': 0.0163994783092087,\n",
       "         'г': 0.01576617989779992,\n",
       "         'ч': 0.01334459387227128,\n",
       "         'я': 0.0183536806995788,\n",
       "         'ш': 0.007337025079643369,\n",
       "         'й': 0.009010711765837806,\n",
       "         'ф': 0.0012785700540933484,\n",
       "         'п': 0.020499882405764256,\n",
       "         'ж': 0.009185178850142183,\n",
       "         'у': 0.022912916123238758,\n",
       "         'э': 0.0028427871971948428,\n",
       "         'ц': 0.0026392422655064037,\n",
       "         'ю': 0.005262662761112655,\n",
       "         'б': 0.014550896923307178,\n",
       "         'щ': 0.002380962562271493,\n",
       "         'ъ': 0.0002971927048812298,\n",
       "         'ё': 0.00019755831605054413})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Подсчёт частот по корпусам\"\"\"\n",
    "calc_frequenties(rus_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:35.113566Z",
     "start_time": "2020-06-24T05:53:35.109566Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Лукъяненко, Линия грёз\"\"\"\n",
    "sample_text_raw = '''\n",
    "Больше всего Кей не любил детей. Сказалось ли на этом его собственное детство – в приюте «Новое поколение» на Альтосе, неизвестно. Как бы там ни было, он никогда не задерживался на одной планете больше девяти месяцев. На тех планетах, которые во время Смутной Войны прошли фертильную обработку, и честно служили поставщиками пушечного мяса для Империи, он не задерживался более четырех с половиной месяцев.\n",
    "Кроме этого Кей не любил, когда его убивали. Порой это было крайне болезненно, и всегда – связано с немалыми тратами. А деньги Кею были нужны. Он любил свой гиперкатер – требующий дорогостоящего ухода, женщин – не требующих столь многого, вина Империи и Мршанской ассоциации, запахи работы старых Клаконских мастеров и те удовольствия прочих рас, которые способен понять и выдержать человек.\n",
    "Сейчас две его антипатии сложились воедино. И самым неприятным было не то, что его собирался убить ребенок, из‑за ребенка, и одним из самых неприятных способов. Беда была в том, что Кей не успел оплатить продление аТана.\n",
    "'''\n",
    "sample_text = filter_text(sample_text_raw, alphabet) # # Очищенный текст примера\n",
    "ciphered_sample_text = cipher(sample_text, get_cipher_dict(alphabet)) # Зашифрованный текст примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:35.612679Z",
     "start_time": "2020-06-24T05:53:35.114568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оригинальный текст\n",
      "\n",
      " больше всего кей не любил детей сказалось ли на этом его собственное детство в приюте новое поколение на альтосе неизвестно как бы там ни было он никогда не задерживался на одной планете больше девяти месяцев на тех планетах которые во время смутной войны прошли фертильную обработку и честно служили поставщиками пушечного мяса для империи он не задерживался более четырех с половиной месяцев кроме этого кей не любил когда его убивали порой это было крайне болезненно и всегда связано с немалыми тратами а деньги кею были нужны он любил свой гиперкатер требующий дорогостоящего ухода женщин не требующих столь многого вина империи и мршанской ассоциации запахи работы старых клаконских мастеров и те удовольствия прочих рас которые способен понять и выдержать человек сейчас две его антипатии сложились воедино и самым неприятным было не то что его собирался убить ребенок из за ребенка и одним из самых неприятных способов беда была в том что кей не успел оплатить продление атана \n",
      "\n",
      "\n",
      "Зашифрованный текст\n",
      "\n",
      " فحػؤصغضخسغقحضؼغشضؽغضػذفؾػضمغرغشضسؼكطكػحسؤضػؾضؽكضجرحȔضغقحضسحفسرخغؽؽحغضمغرسرخحضخضةتؾذرغضؽحخحغضةحؼحػغؽؾغضؽكضكػؤرحسغضؽغؾطخغسرؽحضؼكؼضفئضركȔضؽؾضفئػحضحؽضؽؾؼحقمكضؽغضطكمغتثؾخكػسعضؽكضحمؽحشضةػكؽغرغضفحػؤصغضمغخعرؾضȔغسعـغخضؽكضرغبضةػكؽغركبضؼحرحتئغضخحضختغȔعضسȔارؽحشضخحشؽئضةتحصػؾضظغترؾػؤؽاذضحفتكفحرؼاضؾضإغسرؽحضسػاثؾػؾضةحسركخدؾؼكȔؾضةاصغإؽحقحضȔعسكضمػعضؾȔةغتؾؾضحؽضؽغضطكمغتثؾخكػسعضفحػغغضإغرئتغبضسضةحػحخؾؽحشضȔغسعـغخضؼتحȔغضجرحقحضؼغشضؽغضػذفؾػضؼحقمكضغقحضافؾخكػؾضةحتحشضجرحضفئػحضؼتكشؽغضفحػغطؽغؽؽحضؾضخسغقمكضسخعطكؽحضسضؽغȔكػئȔؾضرتكركȔؾضكضمغؽؤقؾضؼغذضفئػؾضؽاثؽئضحؽضػذفؾػضسخحشضقؾةغتؼكرغتضرتغفاذدؾشضمحتحقحسرحعدغقحضابحمكضثغؽدؾؽضؽغضرتغفاذدؾبضسرحػؤضȔؽحقحقحضخؾؽكضؾȔةغتؾؾضؾضȔتصكؽسؼحشضكسسحـؾكـؾؾضطكةكبؾضتكفحرئضسركتئبضؼػكؼحؽسؼؾبضȔكسرغتحخضؾضرغضامحخحػؤسرخؾعضةتحإؾبضتكسضؼحرحتئغضسةحسحفغؽضةحؽعرؤضؾضخئمغتثكرؤضإغػحخغؼضسغشإكسضمخغضغقحضكؽرؾةكرؾؾضسػحثؾػؾسؤضخحغمؾؽحضؾضسكȔئȔضؽغةتؾعرؽئȔضفئػحضؽغضرحضإرحضغقحضسحفؾتكػسعضافؾرؤضتغفغؽحؼضؾطضطكضتغفغؽؼكضؾضحمؽؾȔضؾطضسكȔئبضؽغةتؾعرؽئبضسةحسحفحخضفغمكضفئػكضخضرحȔضإرحضؼغشضؽغضاسةغػضحةػكرؾرؤضةتحمػغؽؾغضكركؽك \n",
      "\n",
      "\n",
      "Расшифрованный текст\n",
      "\n",
      " колбюе рсеьо деы не лйкал петеы сдижилосб ла ни щтом еьо сокстренное петстро р увайте норое уодоленае ни илбтосе неажрестно дид кя тим на кяло он надоьпи не жипевхарилсг ни опноы улинете колбюе пергта месгцер ни теч улинетич дотовяе ро рвемг смзтноы роыня увоюла февталбнзй оквикотдз а шестно слзхала уостирэадима узюешноьо мгси плг амуеваа он не жипевхарилсг колее шетявеч с уолораноы месгцер двоме щтоьо деы не лйкал доьпи еьо зкарила уовоы щто кяло двиыне колежненно а рсеьпи сргжино с немиляма твитима и пенбьа дей кяла нзхня он лйкал сроы ьауевдитев твекзйэаы повоьостогэеьо зчопи хенэан не твекзйэач столб мноьоьо рани амуеваа а мвюинсдоы иссоцаицаа жиуича викотя стивяч длидонсдач мистевор а те зпоролбстраг увошач вис дотовяе суосокен уонгтб а ряпевхитб шелоред сеышис пре еьо интауитаа слохаласб роепано а симям неувагтням кяло не то што еьо сокавилсг зкатб векенод аж жи векенди а опнам аж симяч неувагтняч суосокор кепи кяли р том што деы не зсуел оулитатб увопленае итини \n",
      "\n",
      "\n",
      "\n",
      "Доля правильно расшифрованных букв 0.5645981688708036\n"
     ]
    }
   ],
   "source": [
    "deciphered_text = freque_decipher(rus_text, ciphered_sample_text, 1)\n",
    "print('Оригинальный текст\\n\\n', sample_text, \"\\n\\n\")\n",
    "print('Зашифрованный текст\\n\\n', ciphered_sample_text, \"\\n\\n\")\n",
    "print('Расшифрованный текст\\n\\n', deciphered_text, \"\\n\\n\\n\")\n",
    "print('Доля правильно расшифрованных букв', get_letter_accuracy(sample_text, deciphered_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Биграммы\n",
    "\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:36.189810Z",
     "start_time": "2020-06-24T05:53:35.613680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расшифрованный текст\n",
      "\n",
      " кпо ао  вояа исне о заотркавнин с еол  чрали   вытоолояа сме к ал по аве кла   ор ено  плао одмпоално   вл  точо  нми р к а ие нем трое и емйа нее нм оы е о осоносетл оле  внн пн овв нно епо ао авреаи ежодотее  втиг овв норг и тотяо  а  завл слбо пна абд  ороули кноапу лнуенен коин си тж к а спсспри од кршас ели осавд пяа езв варлстлено и нее о осоносетл олнепоыо ттедзаг с опо    пнаежодоте ироно ытояа исне о заотр и оы вояа зоттл и одр наыта емйа ин д о епоы  нл а и  воны  с яос а се нвл ери тн орли  вааледи иаинемли  яад енетзаотр сланаднено тнно тзаснуаснааирвя  точаояа зхиы вшаласае о тзаснуасг стоорае пя яа   т втлено и и ехсвасм наибомкускли ос зни н кои  скраяг ивем ес егоео кнооеси то зтвлпо  келл орокегон ю и тотяо с дчмеал одеесрси  воноитаратмй  р  сскюоюка о ояа ваакктаки сй спродрь а х  а и силеое нер еогоонемйа  о та тта ояа смотнл олизоторазаса п стиео взасал  ви ннаности силсге нер еогог с дчмкоенеоы вем  в  тоолтта исне о зоегченмвтакор оронбално торть \n",
      "\n",
      "\n",
      "\n",
      "Доля правильно расшифрованных букв 0.18819938962360122\n"
     ]
    }
   ],
   "source": [
    "deciphered_text_bi = freque_decipher(rus_text, ciphered_sample_text, 2)\n",
    "print('Расшифрованный текст\\n\\n', deciphered_text_bi, \"\\n\\n\\n\")\n",
    "print('Доля правильно расшифрованных букв', get_letter_accuracy(sample_text, deciphered_text_bi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MCMC\n",
    "\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "\n",
    "* предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "* реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем считать что текст представляет собой марковскую цепь, то есть следующий символ зависит от предыдущих. \n",
    "\n",
    "* Инициализируем перестановку маппинга отдельных букв частотным способом, над этим маппингом и будем работать\n",
    "* На каждом шаге алгоритма будем считать правдподобие данной перестановки в зависимости от заданного числа N-грамм. (Для этого придётся применять маппинг на зашифрованный текст и заново для него считать частоты N-грамм)\n",
    "* Если правдоподобие перестановки больше, текущее, принимаем её. В противном случае, принимаем её, с вероятностью new_likelihood/old_likelihood)\n",
    "* Выдаём лучшую найденную перестановку по правдоподобию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:36.199811Z",
     "start_time": "2020-06-24T05:53:36.191810Z"
    }
   },
   "outputs": [],
   "source": [
    "class MCMCModel:\n",
    "    def __init__(self, etalon_text, n_gram = 2, n_iter = 50000):\n",
    "        self.unifreqs = calc_frequenties(etalon_text, 1)\n",
    "        self.freqs = calc_frequenties(etalon_text, n_gram) if n_gram > 1 else self.unifreqs\n",
    "        self.n_gram = n_gram\n",
    "        self.n_iter = n_iter     \n",
    "        pass \n",
    "        \n",
    "    def log_likelihood(self, text):\n",
    "        ngram_counter = get_ngram_count(text, self.n_gram)\n",
    "        none_freq = min(self.freqs.values()) / 2\n",
    "        result = 0\n",
    "        for ngram, count in ngram_counter.items():\n",
    "            freq = self.freqs.get(ngram)\n",
    "            if freq is None:\n",
    "                freq = none_freq\n",
    "                none_freq /= 2 \n",
    "            result += count * np.log(freq)\n",
    "        return result\n",
    "    \n",
    "    def get_random_permute_2_symbols_dict(self, decipher_dict):\n",
    "        perm_decipher_dict = decipher_dict.copy()\n",
    "        k1, k2 = np.random.choice(list(perm_decipher_dict.keys()), 2, replace=False)\n",
    "        perm_decipher_dict[k1], perm_decipher_dict[k2] = perm_decipher_dict[k2], perm_decipher_dict[k1]\n",
    "        return perm_decipher_dict\n",
    "   \n",
    "    def fit(self, ciphered_text):\n",
    "        decipher_dict = get_map_dict(self.unifreqs, calc_frequenties(ciphered_text, 1))\n",
    "        best_decipher_dict = decipher_dict\n",
    "        max_llh = self.log_likelihood(cipher(ciphered_text, decipher_dict))\n",
    "        cur_llh = max_llh\n",
    "        for i in trange(self.n_iter):\n",
    "            new_decipher_dict = self.get_random_permute_2_symbols_dict(decipher_dict)\n",
    "            new_text = cipher(ciphered_text, new_decipher_dict)\n",
    "            new_llh = self.log_likelihood(new_text)\n",
    "            if new_llh > cur_llh or np.random.rand() < np.exp(new_llh - cur_llh):\n",
    "                decipher_dict = new_decipher_dict\n",
    "                cur_llh = new_llh\n",
    "                if cur_llh > max_llh:\n",
    "                    max_llh = cur_llh\n",
    "                    best_decipher_dict = decipher_dict\n",
    "        self.decipher_dict = best_decipher_dict\n",
    "        return self\n",
    "    \n",
    "    def predict(self, ciphered_text):\n",
    "        return cipher(ciphered_text, self.decipher_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:53:52.290442Z",
     "start_time": "2020-06-24T05:53:36.200812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [00:15<00:00, 1330.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " больше всего кей не любил детей сказалось ли на этом его собственное детство в приюте новое поколение на альтосе неизвестно как бы там ни было он никогда не задерживался на одной планете больше девяти месяцев на тех планетах которые во время смутной войны прошли фертильную обработку и честно служили поставщиками пушечного мяса для империи он не задерживался более четырех с половиной месяцев кроме этого кей не любил когда его убивали порой это было крайне болезненно и всегда связано с немалыми тратами а деньги кею были нужны он любил свой гиперкатер требующий дорогостоящего ухода женщин не требующих столь многого вина империи и мршанской ассоциации запахи работы старых клаконских мастеров и те удовольствия прочих рас которые способен понять и выдержать человек сейчас две его антипатии сложились воедино и самым неприятным было не то что его собирался убить ребенок из за ребенка и одним из самых неприятных способов беда была в том что кей не успел оплатить продление атана \n",
      "\n",
      "Доля правильно расшифрованных букв 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MCMCModel(rus_text, n_gram=2, n_iter=20000)\n",
    "deciphered_text_mcmc = model.fit(ciphered_sample_text).predict(ciphered_sample_text)\n",
    "print(\"\\n\", deciphered_text_mcmc, \"\\n\")\n",
    "print('Доля правильно расшифрованных букв', get_letter_accuracy(sample_text, deciphered_text_mcmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Расшифруйте сообщение:\n",
    "\n",
    "```\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n",
    "```\n",
    "Или это (они одинаковые, но сообщали о проблемах с юникодом):\n",
    "```\n",
    "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:54:03.132888Z",
     "start_time": "2020-06-24T05:53:52.290442Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [00:09<00:00, 2043.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " если вы видите нормальный или почти нормальный текст у штого сообжения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обежаю \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "task_text = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\"\n",
    "model = MCMCModel(rus_text, n_gram=3, n_iter=20000)\n",
    "deciphered_task_text_mcmc = model.fit(task_text).predict(task_text)\n",
    "print(\"\\n\", deciphered_task_text_mcmc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На коротких текстах вроде текста задания может потребоваться несколько запусков для получения внятного результата, так как функция, бывает, прыгает в локальные максимумы и уже не выбирается из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Бонус\n",
    "\n",
    "> а что если от биграмм перейти к триграммам (тройкам букв) или даже больше? Улучшатся ли результаты? Когда улучшатся, а когда нет? Чтобы ответить на этот вопрос эмпирически, уже может понадобиться погенерировать много тестовых перестановок и последить за метриками, глазами может быть и не видно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код задания написан таким образом, что переход к ngram'ам делается простым изменением параметра n_gram. Кстати, ответ на задание был получен именно при `n_gram=3`, при этом значении расшифровать ответ получается чаще, чем при 2.\n",
    "\n",
    "Для примера - расчёт на n_grams=4 (гораздо больше локальных максимумов, требуется много перезапусков)\n",
    "\n",
    "2ю часть бонуса с генерацией множества тестовых перестановок не выполнял."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:56:05.688241Z",
     "start_time": "2020-06-24T05:55:43.266182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 20000/20000 [00:21<00:00, 937.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " если вы видите нормальный или почти нормальный текст у штого сообжения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обежаю \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "task_text = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\"\n",
    "model = MCMCModel(rus_text, n_gram=4, n_iter=20000)\n",
    "deciphered_task_text_mcmc = model.fit(task_text).predict(task_text)\n",
    "print(\"\\n\", deciphered_task_text_mcmc, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Бонус\n",
    ">какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T05:48:28.262085Z",
     "start_time": "2020-06-24T05:48:28.258084Z"
    }
   },
   "source": [
    "Например, можно использовать эту модель для (полу)автоматического определения кодировки текстового файла(предварительно, конечно, придётся для такой программы создать наборы частот для каждого поддерживаемого языка)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "526px",
    "left": "2185px",
    "right": "20px",
    "top": "120px",
    "width": "355px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
